{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Playing games!"]},{"cell_type":"markdown","metadata":{},"source":["In this assignment your task is to make computer play games. Of course, we limit ourselves to a very limited subset of games: two players, zero sum, perfect information, deterministic games. These properties may require some explanation:\n","\n","* *Two players* is pretty straightforward: there are exactly two players. Any less is a puzzle (see previous classes), any more is interesting (but out of scope).\n","* *Zero sum* means that a win of one player is necessarly a loss of the other player. For example, if one player wins the game having 100 points, the other player must have exactly -100 points.\n","* *Perfect information* means that there are no hidden variables in the game, like some cards kept in secret by players. Both players can see exactly the same thing.\n","* *Deterministic* means that there is no randomness in the game, no dices, no decks of cards, etc.\n","\n","Each and every of these assumptions can be relaxed, yielding a more complex variant of the problem of playing games."]},{"cell_type":"markdown","metadata":{},"source":["## Game\n","\n","We begin by defining a general class `Game`, equipped with 7 functions:\n","\n","* `initial_state` returns a representation of an intial state of the game, e.g., an empty board and an information which player plays first. State is opaque to search algorithms, similarly as in the classes on Agents and A*.\n","* `player` return the id of a player to make a move in the given `state`. Here we consistently use number 1 to represent the first player and 2 to represent the second player, but in general any two distict identifiers would suffice.\n","* `actions` returns a list of valid moves in the given state. This corresponds to the list of available actions in previous classes.\n","* `result` returns a new state after performing the given `action` in the given `state`. This is the transition model underpinning the game.\n","* `is_terminal` returns `True` if the given `state` is a terminal node in the search tree, i.e., either one of the players won or it is a draw. This is a leaf in a search tree and no further actions can be executed.\n","* `utility` can be called only for a terminal `state` and returns a numeric representation of how good this state is for the given `player`. Because we are considering zero-sum games it is always true that `utility(state, 1) = -utility(state, 2)`\n","* `print_state` is a helper function to pretty-print the given `state` to the standard output. As the representation is opaque and possibly hard to read for a human, this little function will make our lives much easier further down the line."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["class Game:\n","    @property\n","    def initial_state(self):\n","        ...\n","        return state\n","    \n","    def player(self, state):\n","        ...\n","        return playerno\n","        \n","    def actions(self, state):\n","        ...\n","        return actions\n","        \n","    def result(self, state, action):\n","        ...\n","        return new_state\n","        \n","    def is_terminal(self, state):\n","        ...\n","        return boolean\n","        \n","    def utility(self, state, player):\n","        ...        \n","        return number\n","        \n","    def print_state(self, state):\n","        ...        "]},{"cell_type":"markdown","metadata":{},"source":["For convenience we define a simple function `opponent` that, given a player id, returns the id of the other player."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def opponent(player):    \n","    assert player in {1, 2}\n","    if player == 1:\n","        return 2\n","    else:\n","        return 1"]},{"cell_type":"markdown","metadata":{},"source":["## Tic-Tac-Toe\n","\n","The first game we'll consider is *Tic-Tac-Toe* (*noughts and crosses*) in its bare minimum. For completeness, let me quote [Wikipedia](https://en.wikipedia.org/w/index.php?title=Tic-tac-toe&oldid=986503204) on rules: \n","\n","> Tic-tac-toe (American English), noughts and crosses (Commonwealth English), or Xs and Os, is a paper-and-pencil game for two players, X and O, who take turns marking the spaces in a 3×3 grid. The player who succeeds in placing three of their marks in a horizontal, vertical, or diagonal row is the winner. It is a solved game with a forced draw assuming best play from both players."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class TicTacToe(Game):    \n","    @property\n","    def initial_state(self):\n","        return (1, (0,)*9)\n","    \n","    def player(self, state):\n","        return state[0]\n","        \n","    def actions(self, state):\n","        return [i for i, v in enumerate(state[1]) if v == 0]\n","        \n","    def result(self, state, action):\n","        board = state[1]\n","        assert board[action] == 0\n","        assert state[0] in {1, 2}\n","        board = board[:action] + (state[0],) + board[action+1:]\n","        next_player = opponent(state[0])        \n","        return (next_player, board)\n","        \n","    def _has_line(self, state, player):\n","        board = state[1]\n","        for i in [0, 3, 6]:\n","            if board[i] == board[i+1] == board[i+2] == player:\n","                return True\n","        for i in [0, 1, 2]:\n","            if board[i] == board[i+3] == board[i+6] == player:\n","                return True\n","        if board[0] == board[3+1] == board[2*3+2] == player:\n","            return True\n","        if board[2] == board[3+1] == board[2*3] == player:\n","            return True\n","        return False\n","        \n","    def is_terminal(self, state):\n","        if all([v != 0 for v in state[1]]):\n","            return True\n","        return self._has_line(state, 1) or self._has_line(state, 2)\n","    \n","    def utility(self, state, player):\n","        assert player in {1, 2}\n","        mine = self._has_line(state, player)\n","        opponents = self._has_line(state, opponent(player))\n","        if mine and not opponents:\n","            return 1\n","        if not mine and opponents:\n","            return -1\n","        return 0    \n","    \n","    def print_state(self, state):\n","        print(\"Player making move\", \" OX\"[state[0]])\n","        board = [\"_OX\"[v] for v in state[1]]\n","        print(*board[0:3])\n","        print(*board[3:6])\n","        print(*board[6:9])"]},{"cell_type":"markdown","metadata":{},"source":["The actions are represented by the number of field where to put a mark, using the following map:\n","```\n","0|1|2\n","-----\n","3|4|5\n","-----\n","6|7|8\n","```\n","\n","The cell below executes a sequence of actions that leads to a draw."]},{"cell_type":"code","execution_count":4,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","_ _ _\n","_ _ _\n","_ _ _\n","Player making move X\n","_ _ _\n","_ O _\n","_ _ _\n","Player making move O\n","X _ _\n","_ O _\n","_ _ _\n","Player making move X\n","X _ _\n","_ O _\n","O _ _\n","Player making move O\n","X _ X\n","_ O _\n","O _ _\n","Player making move X\n","X O X\n","_ O _\n","O _ _\n","Player making move O\n","X O X\n","_ O _\n","O X _\n","Player making move X\n","X O X\n","_ O O\n","O X _\n","Player making move O\n","X O X\n","X O O\n","O X _\n","Player making move X\n","X O X\n","X O O\n","O X O\n","Reached terminal state? True\n","Utility for the 1st player 0\n","Utility for the 2nd player 0\n"]}],"source":["game = TicTacToe()\n","state = game.initial_state\n","game.print_state(state)\n","\n","for action in [4,0,6,2,1,7,5,3,8]:\n","    assert action in game.actions(state)\n","    assert not game.is_terminal(state)\n","    state = game.result(state, action)\n","    game.print_state(state)\n","    \n","print(\"Reached terminal state?\", game.is_terminal(state))\n","print(\"Utility for the 1st player\", game.utility(state, 1))\n","print(\"Utility for the 2nd player\", game.utility(state, 2))"]},{"cell_type":"markdown","metadata":{},"source":["Below, 2 plays suboptimally and loses."]},{"cell_type":"code","execution_count":5,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","_ _ _\n","_ _ _\n","_ _ _\n","Player making move X\n","_ _ _\n","_ O _\n","_ _ _\n","Player making move O\n","X _ _\n","_ O _\n","_ _ _\n","Player making move X\n","X _ _\n","_ O _\n","O _ _\n","Player making move O\n","X _ X\n","_ O _\n","O _ _\n","Player making move X\n","X O X\n","_ O _\n","O _ _\n","Player making move O\n","X O X\n","_ O _\n","O _ X\n","Player making move X\n","X O X\n","_ O _\n","O O X\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n"]}],"source":["game = TicTacToe()\n","state = game.initial_state\n","game.print_state(state)\n","\n","for action in [4,0,6,2,1,8,7]:\n","    assert action in game.actions(state)\n","    assert not game.is_terminal(state)\n","    state = game.result(state, action)\n","    game.print_state(state)\n","    \n","print(\"Reached terminal state?\", game.is_terminal(state))\n","print(\"Utility for the 1st player\", game.utility(state, 1))\n","print(\"Utility for the 2nd player\", game.utility(state, 2))"]},{"cell_type":"markdown","metadata":{},"source":["Finally, in the cell below 1 plays suboptimally and loses."]},{"cell_type":"code","execution_count":6,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","_ _ _\n","_ _ _\n","_ _ _\n","Player making move X\n","_ _ O\n","_ _ _\n","_ _ _\n","Player making move O\n","_ _ O\n","_ X _\n","_ _ _\n","Player making move X\n","_ _ O\n","_ X _\n","O _ _\n","Player making move O\n","X _ O\n","_ X _\n","O _ _\n","Player making move X\n","X _ O\n","_ X _\n","O O _\n","Player making move O\n","X _ O\n","_ X _\n","O O X\n","Reached terminal state? True\n","Utility for the 1st player -1\n","Utility for the 2nd player 1\n"]}],"source":["game = TicTacToe()\n","state = game.initial_state\n","game.print_state(state)\n","\n","for action in [2,4,6,0,7,8]:\n","    assert action in game.actions(state)\n","    assert not game.is_terminal(state)\n","    state = game.result(state, action)\n","    game.print_state(state)\n","    \n","print(\"Reached terminal state?\", game.is_terminal(state))\n","print(\"Utility for the 1st player\", game.utility(state, 1))\n","print(\"Utility for the 2nd player\", game.utility(state, 2))"]},{"cell_type":"markdown","metadata":{},"source":["## A judge and a dummy"]},{"cell_type":"markdown","metadata":{},"source":["Lets define a common interface for a player: it is a callable (e.g., a function) receiving two arguments: \n","\n","1. The definition of a game as an object of the class `Game`\n","2. A current state in which a move is to be made.\n","\n","The following function `dummy` follows this interface. It represents a player that always makes the first available move."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def dummy(game, state):\n","    return game.actions(state)[0]"]},{"cell_type":"markdown","metadata":{},"source":["To test players it is convenient to construct a general judge with three parameters:\n","\n","* `game` A definition of a game of type `Game`.\n","* `player1` A callable following the interface described above representing the first player.\n","* `player2` A callable following the interface described above representing the second player."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from IPython import display\n","from time import sleep\n","\n","def judge(game: Game, player1, player2):    \n","    state = game.initial_state\n","\n","    while not game.is_terminal(state):\n","        if game.player(state) == 1:\n","            action = player1(game, state)\n","        else:\n","            action = player2(game, state) \n","        display.clear_output(wait = True);        \n","        game.print_state(state)\n","        sleep(0.2)\n","        print(\"Action:\", action)\n","        print()\n","        state = game.result(state, action)\n","     \n","    game.print_state(state)\n","    print(\"Reached terminal state?\", game.is_terminal(state))\n","    u1 = game.utility(state, 1)\n","    u2 = game.utility(state, 2)\n","    print(\"Utility for the 1st player\", u1)\n","    print(\"Utility for the 2nd player\", u2)\n","    if u1 > u2:\n","        print(\"Winner: 1st player\")\n","    elif u1 < u2:\n","        print(\"Winner: 2nd player\")\n","    else:\n","        print(\"Draw\")"]},{"cell_type":"markdown","metadata":{},"source":["Lets see how well two dummies compete against each other in the game of Tic-Tac-Toe."]},{"cell_type":"code","execution_count":9,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","O X O\n","X O X\n","_ _ _\n","Action: 6\n","\n","Player making move X\n","O X O\n","X O X\n","O _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n"]}],"source":["judge(TicTacToe(), dummy, dummy)"]},{"cell_type":"markdown","metadata":{},"source":["## Task 1: Minimax algorithm\n","\n","Complete the following cell with an implementation of the mini-max algorithm. \n","The function should follow the interface for a player described above and return the best move to be made in the given `state` under the rules defined by the `game`."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def maxValue(game: Game, state, player):\n","    u = 'toMax'\n","    if game.is_terminal(state):\n","        return game.utility(state, player), None\n","    \n","    for action in game.actions(state):\n","        u2, move1 = minValue(game, game.result(state, action), player)\n","        if u == 'toMax' or u2 > u:\n","            u, move = u2, action\n","    return u, move\n","\n","def minValue(game: Game, state, player):\n","    u = 'toMin'\n","    if game.is_terminal(state):\n","        return game.utility(state, player), None\n","    \n","    for action in game.actions(state):\n","        u2, move1 = maxValue(game, game.result(state, action), player)\n","        if u == 'toMin' or u2 < u:\n","            u, move = u2, action\n","    return u, move\n","\n","def minimax(game: Game, state):\n","    player = game.player(state)\n","    value, move = maxValue(game, state, player)\n","    # print(value, move)\n","    return move\n","\n","    ..."]},{"cell_type":"markdown","metadata":{},"source":["Lets test your implementation against dummy and against itself. It should always win with dummy (dummy is deterministic and suboptimal) and it should draw with itself (Tic-Tac-Toe is a solved game and draw is the best outcome for optimal players).\n","We prefix the calls to `judge` with `%time` to measure time spent in the call. This will be useful to compare the performance of minimax with alpha-beta."]},{"cell_type":"code","execution_count":11,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","O X X\n","O O X\n","_ _ _\n","Action: 6\n","\n","Player making move X\n","O X X\n","O O X\n","O _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n","CPU times: total: 1.78 s\n","Wall time: 3.18 s\n"]}],"source":["%time judge(TicTacToe(), minimax, dummy)"]},{"cell_type":"code","execution_count":12,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move X\n","O O X\n","O X _\n","_ _ _\n","Action: 6\n","\n","Player making move O\n","O O X\n","O X _\n","X _ _\n","Reached terminal state? True\n","Utility for the 1st player -1\n","Utility for the 2nd player 1\n","Winner: 2nd player\n","CPU times: total: 234 ms\n","Wall time: 1.41 s\n"]}],"source":["%time judge(TicTacToe(), dummy, minimax)"]},{"cell_type":"code","execution_count":13,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","O O X\n","X X O\n","O X _\n","Action: 8\n","\n","Player making move X\n","O O X\n","X X O\n","O X O\n","Reached terminal state? True\n","Utility for the 1st player 0\n","Utility for the 2nd player 0\n","Draw\n","CPU times: total: 1.91 s\n","Wall time: 3.73 s\n"]}],"source":["%time judge(TicTacToe(), minimax, minimax)"]},{"cell_type":"markdown","metadata":{},"source":["## Task 2: Alpha-beta\n","\n","Mini-max is an optimal solution, but not the most efficient. Complete the following cell of code implementing the alpha-beta algorithm.\n","The function should follow the interface for a player described above and return the best move to be made in the given `state` under the rules defined by the `game`."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def maxValueAB(game: Game, state, player, alfa, beta):\n","    u = 'toMax'\n","    if game.is_terminal(state):\n","        return game.utility(state, player), None\n","    \n","    for action in game.actions(state):\n","        u2, move1 = minValueAB(game, game.result(state, action), player, alfa, beta)\n","        if u == 'toMax' or u2 > u:\n","            u, move = u2, action\n","            alfa = max(alfa, u)\n","        if u >= beta:\n","            return u, move\n","    return u, move\n","\n","def minValueAB(game: Game, state, player, alfa, beta):\n","    u = 'toMin'\n","    if game.is_terminal(state):\n","        return game.utility(state, player), None\n","    \n","    for action in game.actions(state):\n","        u2, move1 = maxValueAB(game, game.result(state, action), player, alfa, beta)\n","        if u == 'toMin' or u2 < u:\n","            u, move = u2, action\n","            beta = min(beta, u)\n","        if u <= alfa:\n","            return u, move\n","    return u, move\n","def alphabeta(game, state):\n","    player = game.player(state)\n","    value, move = maxValueAB(game, state, player, float('-inf'), float('inf'))\n","    # print(value, move)\n","    return move\n","    ..."]},{"cell_type":"markdown","metadata":{},"source":["Again, lets test your implementation against dummy and against itself. It should behave in exactly the same way as minimax, but be faster."]},{"cell_type":"code","execution_count":15,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","O X X\n","O O X\n","_ _ _\n","Action: 6\n","\n","Player making move X\n","O X X\n","O O X\n","O _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n","CPU times: total: 62.5 ms\n","Wall time: 1.49 s\n"]}],"source":["%time judge(TicTacToe(), alphabeta, dummy)"]},{"cell_type":"code","execution_count":16,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move X\n","O O X\n","O X _\n","_ _ _\n","Action: 6\n","\n","Player making move O\n","O O X\n","O X _\n","X _ _\n","Reached terminal state? True\n","Utility for the 1st player -1\n","Utility for the 2nd player 1\n","Winner: 2nd player\n","CPU times: total: 31.2 ms\n","Wall time: 1.24 s\n"]}],"source":["%time judge(TicTacToe(), dummy, alphabeta)"]},{"cell_type":"code","execution_count":17,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move O\n","O O X\n","X X O\n","O X _\n","Action: 8\n","\n","Player making move X\n","O O X\n","X X O\n","O X O\n","Reached terminal state? True\n","Utility for the 1st player 0\n","Utility for the 2nd player 0\n","Draw\n","CPU times: total: 172 ms\n","Wall time: 1.95 s\n"]}],"source":["%time judge(TicTacToe(), alphabeta, alphabeta)"]},{"cell_type":"markdown","metadata":{},"source":["## Migration"]},{"cell_type":"markdown","metadata":{},"source":["The following cell defines the rules for the game Migration. See https://www.di.fc.ul.pt/~jpn/gv/migration.htm for a complete description of rules. This implementation is somewhat more flexible: instead of using a board of fixed size, the size of a board is defined by the constructor parameter `n`. The first player that cannot move loses."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import math\n","\n","class Migration:\n","    def __init__(self, n):\n","        self.n = n\n","    \n","    @property\n","    def initial_state(self):\n","        board = [[0]*self.n for _ in range(self.n)]\n","        k = math.ceil(self.n/2 - 1)\n","        for y in range(k):\n","            for x in range(y + 1, self.n - y - 1):\n","                board[x][y] = 1    \n","        for x in range(k):\n","            for y in range(x + 1, self.n - x - 1):\n","                board[self.n - x - 1][y] = 2\n","        board = tuple((tuple(row) for row in board))\n","        return (1, board)\n","    \n","    def player(self, state):\n","        return state[0]\n","    \n","    def _is_valid(self, x, y):\n","        return 0 <= x < self.n and 0 <= y < self.n\n","    \n","    def actions(self, state):\n","        board = state[1]\n","        player = self.player(state)\n","        opp = opponent(player)\n","        if player == 1:\n","            dx, dy = 0, 1\n","        else:\n","            assert player == 2\n","            dx, dy = -1, 0\n","        actions = []\n","        for x in range(self.n):\n","            nx = x + dx\n","            for y in range(self.n):\n","                ny = y + dy\n","                if board[x][y] == player and self._is_valid(nx, ny) and board[nx][ny] == 0:\n","                    actions.append((x, y, nx, ny))\n","        return actions\n","    \n","    def result(self, state, action):\n","        x, y, nx, ny = action\n","        player, board = state\n","        board = [list(row) for row in board]\n","        assert board[x][y] == player\n","        assert board[nx][ny] == 0\n","        board[x][y] = 0\n","        board[nx][ny] = player\n","        board = tuple((tuple(row) for row in board))\n","        return (opponent(player), board)\n","    \n","    def is_terminal(self, state):\n","        return len(self.actions(state)) == 0\n","        \n","    def utility(self, state, player):\n","        assert self.is_terminal(state)\n","        if self.player(state) == player:\n","            return -1\n","        else:\n","            return 1\n","        \n","    def print_state(self, state):\n","        print(\"Player making move\", \"_\\u25CB\\u25CF\"[state[0]])\n","        for row in state[1]:\n","            print(*[\"_\\u25CB\\u25CF\"[v] for v in row]) "]},{"cell_type":"markdown","metadata":{},"source":["Let's first see the initial state."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ _ _ _ _ _ _ _\n","○ _ _ _ _ _ _ _\n","○ ○ _ _ _ _ _ _\n","○ ○ ○ _ _ _ _ _\n","○ ○ ○ _ _ _ _ _\n","○ ○ _ ● ● _ _ _\n","○ _ ● ● ● ● _ _\n","_ ● ● ● ● ● ● _\n"]}],"source":["game = Migration(8)\n","state = game.initial_state\n","game.print_state(state)"]},{"cell_type":"markdown","metadata":{},"source":["Now, white makes a move."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[(1, 0, 1, 1), (2, 1, 2, 2), (3, 2, 3, 3), (4, 2, 4, 3), (5, 1, 5, 2), (6, 0, 6, 1)]\n","Player making move ●\n","_ _ _ _ _ _ _ _\n","_ ○ _ _ _ _ _ _\n","○ ○ _ _ _ _ _ _\n","○ ○ ○ _ _ _ _ _\n","○ ○ ○ _ _ _ _ _\n","○ ○ _ ● ● _ _ _\n","○ _ ● ● ● ● _ _\n","_ ● ● ● ● ● ● _\n"]}],"source":["print(game.actions(state))\n","move = game.actions(state)[0]\n","state = game.result(state, move)\n","game.print_state(state)"]},{"cell_type":"markdown","metadata":{},"source":["As this is a turn-taking game, now it is time for black."]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ _ _ _ _ _ _ _\n","_ ○ _ _ _ _ _ _\n","○ ○ _ _ _ _ _ _\n","○ ○ ○ _ _ _ _ _\n","○ ○ ○ _ _ _ _ _\n","○ ○ _ ● ● _ _ _\n","○ _ ● ● ● ● ● _\n","_ ● ● ● ● ● _ _\n"]}],"source":["move = game.actions(state)[5]\n","state = game.result(state, move)\n","game.print_state(state)"]},{"cell_type":"markdown","metadata":{},"source":["Let's see how well alpha-beta fares on a $4 \\times 4$ board. The following cell should terminate within a few seconds."]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ●\n","_ ● _ _\n","_ _ _ ○\n","_ ○ _ _\n","_ _ ● _\n","Action: (3, 2, 2, 2)\n","\n","Player making move ○\n","_ ● _ _\n","_ _ _ ○\n","_ ○ ● _\n","_ _ _ _\n","Reached terminal state? True\n","Utility for the 1st player -1\n","Utility for the 2nd player 1\n","Winner: 2nd player\n"]}],"source":["judge(Migration(4), alphabeta, alphabeta)"]},{"cell_type":"markdown","metadata":{},"source":["A $5 \\times 5$ board is somewhat more challenging, but should still be within reach. The following cell should terminate within, say, 30 seconds at most."]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ ○ _ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ _ ○ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n","CPU times: total: 5.44 s\n","Wall time: 8.87 s\n"]}],"source":["%time judge(Migration(5), alphabeta, alphabeta)"]},{"cell_type":"markdown","metadata":{},"source":["It goes without saying that alpha-beta should beat the dummy. Each of the following two cells should terminate within 30 seconds, and alpha-beta should be the winner."]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ ○ _ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ _ ○ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n","CPU times: total: 4.25 s\n","Wall time: 7.7 s\n"]}],"source":["%time judge(Migration(5), alphabeta, dummy)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ●\n","_ ● ● _ _\n","_ _ _ _ ○\n","_ _ ○ ● ○\n","_ ○ _ _ _\n","_ _ ● _ _\n","Action: (4, 2, 3, 2)\n","\n","Player making move ○\n","_ ● ● _ _\n","_ _ _ _ ○\n","_ _ ○ ● ○\n","_ ○ ● _ _\n","_ _ _ _ _\n","Reached terminal state? True\n","Utility for the 1st player -1\n","Utility for the 2nd player 1\n","Winner: 2nd player\n","CPU times: total: 2.56 s\n","Wall time: 6.57 s\n"]}],"source":["%time judge(Migration(5), dummy, alphabeta)"]},{"cell_type":"markdown","metadata":{},"source":["## Task 3: Alpha-beta with limited depth and heuristic evaluation"]},{"cell_type":"markdown","metadata":{},"source":["Alpha-beta is a complete and optimal algorithm, but still too slow.\n","In practice it is used as a heuristic algorithm: sometimes searching is terminated before reaching a terminal node and some heuristic evaluation of the reached non-terminal state is returned instead of the utility of a terminal state.\n","How to evaluate non-terminal states and how to decide when to terminate search is an extremely rich topic.\n","\n","Complete the cells below:\n","\n","* Implement the function `evaluate` in `MigrationWithHeuristic` such that it returns some evaluation of the given `state` from the point of view of the given `player`. The more promising the state for the player, the higher value should be returned.\n","* Implement the function `__call__` in `HeuristicAlphaBeta` such that it is an implementation of the alpha-beta algorithm, but should the recursion depth reach `self.max_depth` the heuristic evaluation should be returned instead of descending further in the game tree.\n","\n","Minimax and alpha-beta are game-agnostic and thus for them states are opaque. On the other hand `evaluate` is not game-agnostic, but it is also not (strictly speaking) a part of the rules of a game. Still, it needs to access the internals of the state and in the provided implementation of `Migration` the state is a 2-tuple:\n","\n","1. The id of a player to make a move\n","2. The representation of a board as a tuple of tuples, forming an `self.n` $\\times$ `self.n` array. Each element of this tuple of tuples is either:\n","   * 0 - an empty cell\n","   * 1 - a stone of player 1\n","   * 2 - a stone of player 2"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["class MigrationWithHeuristic(Migration):\n","    def evaluate(self, state, player):\n","        moves = 0\n","        moves += len(self.actions(state))\n","        state = list(state)\n","        state[0] = opponent(player)\n","        state = tuple(state)\n","        moves -= len(self.actions(state))\n","        return moves"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["class HeuristicAlphaBeta:\n","\n","    \n","    def __init__(self, max_depth):\n","        self.max_depth = max_depth\n","        \n","    def __call__(self, game, state):\n","        return self.alphabetaH(game, state)\n","\n","    def maxValueABH(self, game: Game, state, player, alfa, beta, depth):\n","        u = 'toMax'\n","        depth += 1\n","\n","        if game.is_terminal(state):\n","            return game.utility(state, player), None\n","\n","        if depth > self.max_depth:\n","            return game.evaluate(state, player), None\n","\n","        for action in game.actions(state):\n","            u2, move1 = self.minValueABH(game, game.result(state, action), player, alfa, beta, depth)\n","            if u == 'toMax' or u2 > u:\n","                u, move = u2, action\n","                alfa = max(alfa, u)\n","            if u >= beta:\n","                return u, move\n","        return u, move\n","\n","    def minValueABH(self, game: Game, state, player, alfa, beta, depth):\n","        u = 'toMin'\n","        depth += 1\n","\n","        if game.is_terminal(state):\n","            return game.utility(state, player), None\n","        \n","        if depth > self.max_depth:\n","            return game.evaluate(state, player), None\n","        \n","        for action in game.actions(state):\n","            u2, move1 = self.maxValueABH(game, game.result(state, action), player, alfa, beta, depth)\n","            if u == 'toMin' or u2 < u:\n","                u, move = u2, action\n","                beta = min(beta, u)\n","            if u <= alfa:\n","                return u, move\n","        return u, move\n","    \n","    def alphabetaH(self, game, state):\n","        player = game.player(state)\n","        value, move = self.maxValueABH(game, state, player, float('-inf'), float('inf'), depth = 0)\n","        # print(value, move)\n","        return move"]},{"cell_type":"markdown","metadata":{},"source":["## Task 4: Comparing alpha-beta and alpha-beta with heuristics"]},{"cell_type":"markdown","metadata":{},"source":["As you have seen $5\\times 5$ board in this game is easy enough for alpha-beta, so we can use it to compare complete alpha-beta and alpha-beta with heuristics. Copy the next two cell a few times, and consider different depths for `HeuristicAlphaBeta`. Keep in mind that the game may be slightly unfair and thus you should always allow every player play in both positions before making conclusions. Afterwards, answer the question below the code cells."]},{"cell_type":"code","execution_count":28,"metadata":{"scrolled":true,"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ ● ● ● _\n","_ _ _ _ ○\n","_ _ ○ _ ○\n","_ _ ○ _ _\n","_ _ ● _ _\n","Action: (2, 2, 2, 3)\n","\n","Player making move ●\n","_ ● ● ● _\n","_ _ _ _ ○\n","_ _ _ ○ ○\n","_ _ ○ _ _\n","_ _ ● _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n","CPU times: total: 1.84 s\n","Wall time: 6.41 s\n"]}],"source":["%time judge(MigrationWithHeuristic(5), HeuristicAlphaBeta(8), alphabeta)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ ○ _ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ _ ○ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n","CPU times: total: 4.5 s\n","Wall time: 7.89 s\n"]}],"source":["%time judge(MigrationWithHeuristic(5), alphabeta, HeuristicAlphaBeta(8))"]},{"cell_type":"markdown","metadata":{},"source":["**Summarize your experiments briefly (what depths did you consider, how long did it took; if you've changed any other parameters from the defaults, specify the new values). Is complete alpha-beta always better than its heuristics variant, or do they become equally good at some point? Why do you think is that?**"]},{"cell_type":"markdown","metadata":{},"source":["I considered 5, 7 and 8 recursion depth. while the algorithm ran quicker 5 than 7 and 7 than 8 however with both 5 and 7 the heuristic always lost with complete alphabeta but on 8 it started winning provided it had the first move. Meaning that with the board size of 5x5 after the maxDepth is higher than 7 then heuristic alfabeta is just as good as complete alfabeta."]},{"cell_type":"markdown","metadata":{},"source":["## Task 5: Comparing different depths of alpha-beta with heuristics"]},{"cell_type":"markdown","metadata":{},"source":["Now, let's switch to the original version of the game on the $8\\times 8$ board. Your heuristics alpha-beta should be capable of playing it against itself within a reasonable time limit (say, 30 seconds per game). Similarly to the previous task, copy the following cell multiple times and fiddle with the depths. Then, answer the question below the code cells."]},{"cell_type":"code","execution_count":30,"metadata":{"scrolled":true,"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Player making move ○\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ ○ _ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Action: (2, 1, 2, 2)\n","\n","Player making move ●\n","_ ● _ ● _\n","_ _ _ _ ○\n","_ _ ○ ○ _\n","_ ○ ● _ _\n","_ _ ● _ _\n","Reached terminal state? True\n","Utility for the 1st player 1\n","Utility for the 2nd player -1\n","Winner: 1st player\n","CPU times: total: 1.48 s\n","Wall time: 4.92 s\n"]}],"source":["\n","%time judge(MigrationWithHeuristic(5), HeuristicAlphaBeta(10), HeuristicAlphaBeta(14))"]},{"cell_type":"markdown","metadata":{},"source":["**Summarize your experiments briefly (what depths did you consider, how long did it took; if you've changed any other parameters from the defaults, specify the new values). Is the alpha-beta searching deeper always better than the shallower one? What about games when two alpha-betas of equal depth play against each other? Is there a clear pattern (e.g., the first/second player always wins), or does it change between different depths and/or differnt executions? Try to come up with an explanation for all the observations.**"]},{"cell_type":"markdown","metadata":{},"source":["For 3x3 board player 2 has no way of winnig, however for 4x4 board it seems that the roles have changed and player 1 has no way of winning. But for the higher boards it seems that there exists a certain depth level (for 5x5 its 10) above which player 1 becomes the favored and wins with player 2 every time, and below that level player 2 always wins given that both players are equally skilled. This depth level seems to grow with the size of the board, for board of 6x6 it's bigger than 10 which was the depth level for 5x5 board however i don't know what it is for 6x6 due to long runtimes. Above that level player 1 wins even if it's outclassed by its oponnent, but below that level the player with better insight (max.depth) wins."]},{"cell_type":"markdown","metadata":{},"source":["Size: 3x3, depth1: 5, depth2: 5 => always player 1 wins\n","\n","Size: 4x4, depth1: 5, depth2: 5 => always player 2 wins\n","\n","Size: 5x5, depth1: 5, depth2: 5 => always player 2 wins\n","\n","Size: 6x6, depth1: 5, depth2: 5 => always player 2 wins\n","\n","Size: 7x7, depth1: 5, depth2: 5 => always player 2 wins\n","\n","Size: 8x8, depth1: 5, depth2: 5 => always player 2 wins \n","\n","Size: 4x4, depth1: 20, depth2: 2 => always player 2 wins \n","\n","Size: 4x4, depth1: 2, depth2: 20 => always player 2 wins \n","\n","Size: 5x5, depth1: 20, depth2: 5 => always player 1 wins (Even though player 2 advantage it still loses because player 1 has much better insight into the game)\n","\n","Size: 5x5, depth1: 5, depth2: 20 => always player 2 wins \n","\n","Size: 5x5, depth1: 10, depth2: 10 => always player 1 wins | Size: 5x5, depth1: 9, depth2: 9 => always player 2 wins \n","\n","Size: 6x6, depth1: 10, depth2: 10 => always player 2 wins | Size: 6x6, depth1: 9, depth2: 9 => always player 2 wins \n","\n","Size: 4x4, depth1: 20, depth2: 20 => always player 2 wins\n","\n","Size: 5x5, depth1: 10, depth2: 8 => always player 1 wins \n","\n","Size: 5x5, depth1: 8, depth2: 10 => always player 2 wins \n","\n","Size: 5x5, depth1: 8, depth2: 6 => always player 1 wins \n","\n","Size: 5x5, depth1: 6, depth2: 8 => always player 2 wins \n","\n","Size: 5x5, depth1: 12, depth2: 10 => always player 1 wins \n","\n","Size: 5x5, depth1: 10, depth2: 12 => always player 1 wins \n","\n","Size: 5x5, depth1: 10, depth2: 14 => always player 1 wins \n","\n","*(for small boards, player 2 is favored but, from bigger boards than 4 it seems that player 1 is favored provided that their game has reached certain level of skill)*\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.11.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"vscode":{"interpreter":{"hash":"c9b9c52f097f58104c4be7fba1ff825a9d71bbcc63f5df2cdf010a1be35fe908"}}},"nbformat":4,"nbformat_minor":4}
